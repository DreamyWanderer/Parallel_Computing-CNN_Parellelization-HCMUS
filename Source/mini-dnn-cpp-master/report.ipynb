{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dl7uj8hyWdZ"
      },
      "source": [
        "# Set up system\n",
        "\n",
        "And running Mini-CNN for runnability testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EXqbXsNlpOF"
      },
      "source": [
        "Check CUDA compiler version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTZtGIK6lsFo",
        "outputId": "4af78b86-fd1e-4346-8a4d-860acde371f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile executable file\n",
        "\n",
        "Set up for compiling demo.exe. If the demo.exe has been put in the correct location: skip belows cell until you have met cell \"RUN THIS\""
      ],
      "metadata": {
        "id": "pHZ3gkmah9Xr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXSFDweYcJ-Q",
        "outputId": "85bbdd77-b461-48ec-af8c-3f45c209254e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/University/Parallel Computing/Personal/mini-dnn-cpp-master\n",
            "\u001b[0m\u001b[01;34mbuild\u001b[0m/          ConvExperiment.cc  demo_Fashion_MNIST.cc  report.ipynb  testImplement.cc\n",
            "CMakeLists.txt  \u001b[01;34mdata\u001b[0m/              LICENSE                \u001b[01;34msrc\u001b[0m/          testImplement.h\n",
            "config.h        demo.cc            readme.md              \u001b[01;34mtest\u001b[0m/         \u001b[01;34mthird_party\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/University/Parallel Computing/Personal/mini-dnn-cpp-master\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsjWN5AtcYcK",
        "outputId": "4a2f8fcb-e528-4941-f969-b1bc941be8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/University/Parallel Computing/Personal/mini-dnn-cpp-master/build\n"
          ]
        }
      ],
      "source": [
        "%rm -r build\n",
        "%mkdir build\n",
        "%cd build\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mc2YkdAqW1_",
        "outputId": "963b3c4c-fc25-4231-b6de-e9ffdc73f2bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- The CUDA compiler identification is NVIDIA 12.2.140\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Configuring done (6.8s)\n",
            "-- Generating done (0.3s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/University/Parallel Computing/Personal/mini-dnn-cpp-master/build\n"
          ]
        }
      ],
      "source": [
        "!cmake .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdwIP5bieHpm",
        "outputId": "1284cfd7-420f-42a3-c5ff-002c11728f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ -5%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/mnist.cc.o\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/network.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/ave_pooling.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/conv.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CUDA object src/CMakeFiles/MiniDNNLib.dir/layer/cuda_utilities.cu.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/fully_connected.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/max_pooling.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/relu.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/sigmoid.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/layer/softmax.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/loss/cross_entropy_loss.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/loss/mse_loss.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/MiniDNNLib.dir/optimizer/sgd.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX static library libMiniDNNLib.a\u001b[0m\n",
            "[ 63%] Built target MiniDNNLib\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/demo.dir/ConvExperiment.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/demo.dir/demo.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/demo.dir/demo_Fashion_MNIST.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/demo.dir/testImplement.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking CXX executable demo\u001b[0m\n",
            "[ 89%] Built target demo\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN THIS"
      ],
      "metadata": {
        "id": "NpnwvdMtBKL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the `./demo.exe` for activating LeNet-5 running on the test set. The `demo.exe` can run with multiple version of Convolutional layer (currently there are 3 versions which are indexed from 0 to 3) on the same test set, by passing follwing arguments:\n",
        "\n",
        "- First argument: the index of the first version you want to execute.\n",
        "- Second argument: the index of final version that `demo.exe` will implement.\n",
        "- Third argument: if `0`, the `demo.exe` only executes the first version. If `1`, the `demo.exe` executes all versions from first one to the final one.\n",
        "\n",
        "Following is the list of implemented versions and theirs index (The first and second arguments can gain below number):\n",
        "\n",
        "- `0` - The sequential version: The forward of Convolutional layer is sequential in the input rolling stage.\n",
        "- `1` - The first parallel version: The forward of Convolutional layer is parallelized in the input rolling stage.\n",
        "- `2` - The second parallel version: The forward of Convolutional layer is parallelizedd in the matrix multiplication between input features and layer's weights.\n",
        "- Any other number - The original implementation of Convolutional layer which is provided as is by authors of `mini-dnn-cpp` project.\n"
      ],
      "metadata": {
        "id": "0_gyYvtHBRI4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xUKBF8M3fVCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8458ac61-05aa-4448-e3b7-768dbdbf233c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CMakeCache.txt\tCMakeFiles  cmake_install.cmake  demo  Makefile  src\n",
            "../data/fashion-mnist/\n",
            "mnist train number: 60000\n",
            "mnist test number: 10000\n",
            "Parameters loaded\n",
            "\n",
            "Current version: 0\n",
            "\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "\n",
            "\n",
            "Test time: 75486.2\n",
            "Test acc: 0.8297\n",
            "\n",
            "------------------------------------------\n",
            "\n",
            "Parameters loaded\n",
            "\n",
            "Current version: 1\n",
            "\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "\n",
            "\n",
            "Test time: 41209.7\n",
            "Test acc: 0.8297\n",
            "\n",
            "------------------------------------------\n",
            "\n",
            "Parameters loaded\n",
            "\n",
            "Current version: 2\n",
            "\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "Test case 0 passed\n",
            "Test case 1 passed\n",
            "Test case 2 passed\n",
            "Test case 3 passed\n",
            "Test case 4 passed\n",
            "Test case 5 passed\n",
            "Test case 6 passed\n",
            "Test case 7 passed\n",
            "Test case 8 passed\n",
            "Test case 9 passed\n",
            "Test cases passed\n",
            "\n",
            "\n",
            "Test time: 32153.9\n",
            "Test acc: 0.8297\n",
            "\n",
            "------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!./demo 0 2 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdGh_rTRXK63"
      },
      "source": [
        "# Describe Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2jdGN8w5kc6"
      },
      "source": [
        "## Source specification\n",
        "\n",
        "- Matrix library name: Eigen\n",
        "- Starting code space: `mini-dnn-cpp` project (provided in project description)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnQZPzrYXTS7"
      },
      "source": [
        "## Convolution Layer using GEMM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic idea"
      ],
      "metadata": {
        "id": "mX4mAQ_fEQJy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4w8O92wXrSq"
      },
      "source": [
        "### Input layout\n",
        "\n",
        "A mini-batch of multiple input images (input features) $X$ as the tensor has shape $(N, C, H, W)$ where:\n",
        "\n",
        "* $N$: number of samples in a mini-batch\n",
        "* $C$: number of input feature maps.\n",
        "* $H$: height of each input feature map (or simply just the height of each input image in pixels).\n",
        "* $W$: width of each input feature map (or simply just the weight of each input image in pixels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2f_Bv2m54P_"
      },
      "source": [
        "### Output layout\n",
        "\n",
        "The output features after applying CNN to $X$. It is an array $Y$ as the tensor has shape $(N, M, H_\\text{out}, W_\\text{out})$ where:\n",
        "\n",
        "* $N$: number of samples in a mini-batch\n",
        "* $M$: number of output feature maps of a CNN layer.\n",
        "* $H_\\text{out}$: height of each output feature map (it is often that $H_\\text{out} = H - K + 1$).\n",
        "* $W_\\text{out}$: width of each output feature map (it is often that $W_\\text{out} = W - K + 1$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWyhdqsj5_DD"
      },
      "source": [
        "### Filter-bank layout\n",
        "\n",
        "The matrix $W$ contains all filer maxtrix that is used for one CNN layer (or simply just the weigth matrix of a CNN layer).  It is a tensor has shape $(M, C, K, K)$ where:\n",
        "\n",
        "* $K$: the size of a filter matrix (or kernel matrix).\n",
        "\n",
        "With an input image has $C$ input feature maps (or $C$ color chanels) and the CNN layer produces $M$ output feature maps from that input feature maps, we need $C \\times M$ kernel matrix with size $K$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm02TxsL6CBN"
      },
      "source": [
        "### The Unrolled-X\n",
        "\n",
        "We unroll the matrix X. As a result, we can get all elements that are required for computing all output feature maps from a single input image, with just a single matrix multiplication step between $X$ and $W$. For now, just know that $X_\\text{unroll}$ is retrieved from $X$, and it has shape $(C, K, K, H_\\text{out}, W_\\text{out})$, where:\n",
        "\n",
        "* $(C, K, K)$: the \"height\" of $X_\\text{unroll}$. It is the number of elements in $X$ that we need to compute an output feature map element (that is $C \\times K \\times K$),\n",
        "* $(H_\\text{out}, W_\\text{out})$: the \"width\" of $X_\\text{unroll}$. It is the number of elements in an output feature map, that is $H_\\text{out} \\times W_\\text{out}$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project assumptions\n",
        "\n",
        "- The stride each time moving the kernel matrix is just $1$. So $H_\\text{out} | W_\\text{out}$ is always equal $H_\\text{in} | W_\\text{in} - K + 1$.\n",
        "- Padding is always $0$. It means we treat two outer rows/columns at border as the ghost cells. As a result, the output feature maps are always smaller than the input ones."
      ],
      "metadata": {
        "id": "ufm4I5bmGHwh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE29-G9xfltj"
      },
      "source": [
        "## Version 0: Naive implementation (Sequential Version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "- transpose() is lazy operation. So use transpose().data() to retrieve 1D array as row-major order from the Matrix is pointless.\n",
        "- When initialize a new"
      ],
      "metadata": {
        "id": "uc5LLWDawgqC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}